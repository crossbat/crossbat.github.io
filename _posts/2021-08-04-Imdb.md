---
layout : post
title : 'Imdb Data ML'
---


```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import os
```

# 파일 경로 지정

```python
imdb_dir = "C:/Users/Windows10/Desktop/data/aclImdb/"

train_pos = os.path.join(imdb_dir, 'train/pos/')
train_neg = os.path.join(imdb_dir, 'train/neg/')

test_pos = os.path.join(imdb_dir, 'test/pos/')
test_neg = os.path.join(imdb_dir, 'test/neg/')

data_path = [train_pos, train_neg, test_pos, test_neg]
```

# 데이터 분리 함수 만들기

```python
from glob import glob

def make_dataframe(path = imdb_dir, data_path = data_path):
    pos = 1
    neg = 0
    label = []
    texts = []
    path_ = []

    for files in data_path:
        if files.find('pos') != -1:
            for text in glob(os.path.join(files, '*')):
                f = open(text, encoding = 'utf-8')
                temp = f.read()
                texts.append(temp)
                f.close()
                label.append(pos)
                path_.append(text)
        else:
            for text in glob(os.path.join(files, '*')):
                f = open(text, encoding= 'utf-8')
                temp = f.read()
                texts.append(temp)
                f.close()
                label.append(neg)
                path_.append(text)
    
    return label, texts, path_

label, texts, path_ = make_dataframe()
```

# 데이터프레임으로 

```python
df = pd.DataFrame({'texts' : texts, 'labels' : label, 'paths': path_})
```


```python
df['paths'][1]
```




    'C:/Users/Windows10/Desktop/data/aclImdb/train/pos\\10000_8.txt'




```python
paths = df.pop('paths')
```


```python
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texts</th>
      <th>labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bromwell High is a cartoon comedy. It ran at t...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Homelessness (or Houselessness as George Carli...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>This is easily the most underrated film inn th...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>This is not the typical Mel Brooks film. It wa...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>I occasionally let my kids watch this garbage ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>When all we have anymore is pretty much realit...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>The basic genre is a thriller intercut with an...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>Four things intrigued me as to this film - fir...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>David Bryce's comments nearby are exceptionall...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>50000 rows × 2 columns</p>
</div>


# 데이터 셔플링

```python
df_shuffle = df.iloc[np.random.permutation(df.index)].reset_index(drop = True)
```


```python
print(df_shuffle)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texts</th>
      <th>labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>I was quite impressed with this movie as a chi...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Steven Seagal....how could you be a part of su...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>My one line summary should explain it all, but...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arg. The shuffling dinosaurs are back to take ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>i know technically this isn't the greatest TV ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>A pretty memorable movie of the animals-killin...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>I can't disagree with a previous comment that ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>John Candy. Need we say more? He is the main r...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>Malcolm McDowell diagnoses Megan Gallagher's d...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>This series adds new information and backgroun...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>50000 rows × 2 columns</p>
</div>


# 데이터 내 특수문자 제거

```python
import re

changed_texts = []
for text in df_shuffle['texts']:
    changed_texts.append(re.sub('[-=+,#/\?:^$.@*\"※~&%ㆍ!』\\‘|\(\)\[\]\<\>`\'…》]', ' ', text))

```


```python
df_shuffle['changed_text'] = changed_texts
```


```python
print(df_shuffle)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texts</th>
      <th>labels</th>
      <th>changed_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>I was quite impressed with this movie as a chi...</td>
      <td>0</td>
      <td>I was quite impressed with this movie as a chi...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Steven Seagal....how could you be a part of su...</td>
      <td>0</td>
      <td>Steven Seagal    how could you be a part of su...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>My one line summary should explain it all, but...</td>
      <td>0</td>
      <td>My one line summary should explain it all  but...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arg. The shuffling dinosaurs are back to take ...</td>
      <td>0</td>
      <td>Arg  The shuffling dinosaurs are back to take ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>i know technically this isn't the greatest TV ...</td>
      <td>1</td>
      <td>i know technically this isn t the greatest TV ...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>A pretty memorable movie of the animals-killin...</td>
      <td>1</td>
      <td>A pretty memorable movie of the animals killin...</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>I can't disagree with a previous comment that ...</td>
      <td>1</td>
      <td>I can t disagree with a previous comment that ...</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>John Candy. Need we say more? He is the main r...</td>
      <td>0</td>
      <td>John Candy  Need we say more  He is the main r...</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>Malcolm McDowell diagnoses Megan Gallagher's d...</td>
      <td>1</td>
      <td>Malcolm McDowell diagnoses Megan Gallagher s d...</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>This series adds new information and backgroun...</td>
      <td>1</td>
      <td>This series adds new information and backgroun...</td>
    </tr>
  </tbody>
</table>
<p>50000 rows × 3 columns</p>
</div>




```python
df_shuffle = df_shuffle.drop('texts', axis = 1)

df_shuffle.columns = ['labels', 'texts']
df_shuffle = df_shuffle[['texts', 'labels']]
```

# 토크나이저로 텍스트를 시퀀스로 

```python
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
```


```python
t = Tokenizer(num_words= 20000)
t.fit_on_texts(df_shuffle['texts'])
seq = t.texts_to_sequences(df_shuffle['texts'])
```


```python
df_com = df_shuffle.copy()
df_com['sequence'] = seq
print(df_com)
```

                                                       texts  labels  \
    0      I was quite impressed with this movie as a chi...       0   
    1      Steven Seagal    how could you be a part of su...       0   
    2      My one line summary should explain it all  but...       0   
    3      Arg  The shuffling dinosaurs are back to take ...       0   
    4      i know technically this isn t the greatest TV ...       1   
    ...                                                  ...     ...   
    49995  A pretty memorable movie of the animals killin...       1   
    49996  I can t disagree with a previous comment that ...       1   
    49997  John Candy  Need we say more  He is the main r...       0   
    49998  Malcolm McDowell diagnoses Megan Gallagher s d...       1   
    49999  This series adds new information and backgroun...       1   
    
                                                    sequence  
    0      [10, 14, 183, 1504, 18, 11, 16, 15, 3, 504, 4,...  
    1      [2092, 2224, 86, 97, 21, 30, 3, 176, 4, 140, 3...  
    2      [59, 29, 348, 2603, 143, 1252, 8, 31, 19, 10, ...  
    3      [1, 19087, 3877, 26, 145, 5, 189, 161, 4372, 4...  
    4      [10, 120, 2661, 11, 214, 22, 1, 808, 239, 117,...  
    ...                                                  ...  
    49995  [3, 184, 891, 16, 4, 1, 1579, 847, 80, 2394, 3...  
    49996  [10, 51, 22, 3017, 18, 3, 928, 919, 12, 1799, ...  
    49997  [311, 1965, 364, 70, 133, 53, 25, 6, 1, 283, 2...  
    49998  [7684, 8724, 10094, 18311, 13, 542, 2, 55, 15,...  
    49999  [11, 203, 1524, 170, 1516, 2, 947, 5, 1, 270, ...  
    
    [50000 rows x 3 columns]
    


```python
train_split = int(len(df_com) * 0.8)

train_data = df_com.iloc[:train_split, :]
test_data = df_com.iloc[train_split:, :]
```


```python
print(train_data)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texts</th>
      <th>labels</th>
      <th>sequence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>I was quite impressed with this movie as a chi...</td>
      <td>0</td>
      <td>[10, 14, 183, 1504, 18, 11, 16, 15, 3, 504, 4,...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Steven Seagal    how could you be a part of su...</td>
      <td>0</td>
      <td>[2092, 2224, 86, 97, 21, 30, 3, 176, 4, 140, 3...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>My one line summary should explain it all  but...</td>
      <td>0</td>
      <td>[59, 29, 348, 2603, 143, 1252, 8, 31, 19, 10, ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arg  The shuffling dinosaurs are back to take ...</td>
      <td>0</td>
      <td>[1, 19087, 3877, 26, 145, 5, 189, 161, 4372, 4...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>i know technically this isn t the greatest TV ...</td>
      <td>1</td>
      <td>[10, 120, 2661, 11, 214, 22, 1, 808, 239, 117,...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>39995</th>
      <td>The worst movie I have seen in quite a while  ...</td>
      <td>0</td>
      <td>[1, 249, 16, 10, 28, 109, 9, 183, 3, 137, 219,...</td>
    </tr>
    <tr>
      <th>39996</th>
      <td>This is a thoroughly enjoyable  well acted fil...</td>
      <td>1</td>
      <td>[11, 6, 3, 1646, 729, 71, 877, 20, 8, 6, 155, ...</td>
    </tr>
    <tr>
      <th>39997</th>
      <td>Nicely done  and along with  New voyages  it s...</td>
      <td>1</td>
      <td>[1768, 221, 2, 343, 18, 170, 8, 13, 3, 81, 105...</td>
    </tr>
    <tr>
      <th>39998</th>
      <td>Quentin Crisp once stated that when things are...</td>
      <td>0</td>
      <td>[5758, 5258, 282, 3527, 12, 52, 181, 26, 605, ...</td>
    </tr>
    <tr>
      <th>39999</th>
      <td>I agree that this film achieved its goals perf...</td>
      <td>1</td>
      <td>[10, 1014, 12, 11, 20, 3249, 92, 6432, 916, 10...</td>
    </tr>
  </tbody>
</table>
<p>40000 rows × 3 columns</p>
</div>




```python
print(test_data)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>texts</th>
      <th>labels</th>
      <th>sequence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>40000</th>
      <td>I get the impression that I was watching a dif...</td>
      <td>0</td>
      <td>[10, 76, 1, 1379, 12, 10, 14, 150, 3, 280, 16,...</td>
    </tr>
    <tr>
      <th>40001</th>
      <td>My paraphrase above of the slogan on the back ...</td>
      <td>0</td>
      <td>[59, 11398, 726, 4, 1, 23, 1, 145, 4, 1, 263, ...</td>
    </tr>
    <tr>
      <th>40002</th>
      <td>What an inspiring movie  I laughed  cried and ...</td>
      <td>1</td>
      <td>[48, 35, 3446, 16, 10, 1440, 3607, 2, 439, 111...</td>
    </tr>
    <tr>
      <th>40003</th>
      <td>This was a horrible film  I gave it 2 Points  ...</td>
      <td>0</td>
      <td>[11, 14, 3, 492, 20, 10, 514, 8, 231, 807, 29,...</td>
    </tr>
    <tr>
      <th>40004</th>
      <td>That  70s Show  is definitely the funniest sh...</td>
      <td>1</td>
      <td>[12, 1830, 117, 6, 410, 1, 1532, 117, 3740, 23...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>49995</th>
      <td>A pretty memorable movie of the animals killin...</td>
      <td>1</td>
      <td>[3, 184, 891, 16, 4, 1, 1579, 847, 80, 2394, 3...</td>
    </tr>
    <tr>
      <th>49996</th>
      <td>I can t disagree with a previous comment that ...</td>
      <td>1</td>
      <td>[10, 51, 22, 3017, 18, 3, 928, 919, 12, 1799, ...</td>
    </tr>
    <tr>
      <th>49997</th>
      <td>John Candy  Need we say more  He is the main r...</td>
      <td>0</td>
      <td>[311, 1965, 364, 70, 133, 53, 25, 6, 1, 283, 2...</td>
    </tr>
    <tr>
      <th>49998</th>
      <td>Malcolm McDowell diagnoses Megan Gallagher s d...</td>
      <td>1</td>
      <td>[7684, 8724, 10094, 18311, 13, 542, 2, 55, 15,...</td>
    </tr>
    <tr>
      <th>49999</th>
      <td>This series adds new information and backgroun...</td>
      <td>1</td>
      <td>[11, 203, 1524, 170, 1516, 2, 947, 5, 1, 270, ...</td>
    </tr>
  </tbody>
</table>
<p>10000 rows × 3 columns</p>
</div>




```python
train_pad = train_data['sequence'].values
test_pad = test_data['sequence'].values
```


```python
train_pad_data = pad_sequences(train_pad, maxlen = 500)
test_pad_data = pad_sequences(test_pad, maxlen = 500)
```


```python
x_train = train_pad_data
x_test = test_pad_data
y_train = train_data['labels'].values
y_test = test_data['labels'].values
```


```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D
```

# 모델 

```python
model = Sequential([
    Embedding(len(t.word_index) + 1, 64, input_shape = (None,)),
    GlobalAveragePooling1D(),
    Dense(32, activation = 'relu'),
    Dense(16, activation = 'relu'),
    Dense(1, activation = 'relu')
])
```


```python
model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])
```


```python
from tensorflow.keras.callbacks import EarlyStopping

es = EarlyStopping(monitor= 'val_loss', mode = 'min', patience= 5)
```


```python
history = model.fit(x_train, y_train, epochs = 20, validation_split = 0.2, callbacks= [es], shuffle = True)
```

    Epoch 1/20
    1000/1000 [==============================] - 41s 40ms/step - loss: 0.4870 - acc: 0.7994 - val_loss: 0.3793 - val_acc: 0.8708
    Epoch 2/20
    1000/1000 [==============================] - 41s 41ms/step - loss: 0.3436 - acc: 0.8978 - val_loss: 0.3408 - val_acc: 0.8947
    Epoch 3/20
    1000/1000 [==============================] - 41s 41ms/step - loss: 0.3254 - acc: 0.9116 - val_loss: 0.3573 - val_acc: 0.9034
    Epoch 4/20
    1000/1000 [==============================] - 41s 41ms/step - loss: 0.3234 - acc: 0.9193 - val_loss: 0.3623 - val_acc: 0.9039
    Epoch 5/20
    1000/1000 [==============================] - 42s 42ms/step - loss: 0.3089 - acc: 0.9234 - val_loss: 0.4278 - val_acc: 0.9040
    Epoch 6/20
    1000/1000 [==============================] - 40s 40ms/step - loss: 0.3093 - acc: 0.9309 - val_loss: 0.4280 - val_acc: 0.8744
    Epoch 7/20
    1000/1000 [==============================] - 40s 40ms/step - loss: 0.3082 - acc: 0.9347 - val_loss: 0.4842 - val_acc: 0.8955
    


```python
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epoch = range(0, len(acc))

plt.figure(figsize = (12, 10))
plt.plot(epoch, acc, 'r-', label = 'acc')
plt.plot(epoch, val_acc, 'b-', label = 'validation acc')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.figure()

plt.plot(epoch, loss, 'r-', label = 'loss')
plt.plot(epoch, val_loss, 'b-', label = 'validation loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()
```

![정확도 그래프](crossbat.github.io/_image/acc.png)

![손실 그래프](crossbat.github.io/_image/loss.png)
